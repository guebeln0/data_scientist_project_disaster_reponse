{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f981ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756aeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    '''\n",
    "    Loads the data from the sql database in database_filepath\n",
    "    return feature as X and results as y\n",
    "\n",
    "    Args:\n",
    "        database_filepath: path to the sql database\n",
    "\n",
    "    returns:\n",
    "        X: panda dataframe : feature: list of messages\n",
    "        y: panda dataframe : result: classification of each message\n",
    "        category_names: list of categories\n",
    "    '''\n",
    "    # load data from database\n",
    "    engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql_table('disaster_messages', engine)\n",
    "\n",
    "    # As feature is used the messages (translated in english)\n",
    "    X = df['message']\n",
    "    # classification for each message\n",
    "    y = df.iloc[:, 3:]\n",
    "\n",
    "    return X, y, y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d1619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, stop_words=set(stopwords.words('english'))):\n",
    "    ''' Remove punctuation, strip unncessary spaces, lematize,\n",
    "    remove stopwords and tokenize text\n",
    "\n",
    "    Args:\n",
    "        text: str\n",
    "    returns:\n",
    "        clean_tokens: list of tokens\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    filtered_tokens = [w for w in tokens if not w.lower() in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for token in filtered_tokens:\n",
    "        clean_token = lemmatizer.lemmatize(token).lower().strip()\n",
    "        clean_tokens.append(clean_token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5688c70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    build the model\n",
    "\n",
    "    Args: None\n",
    "\n",
    "    returns:\n",
    "        pipeline\n",
    "    '''\n",
    "    pipeline = Pipeline([\n",
    "                    ('vect', CountVectorizer(tokenizer=tokenize,  ngram_range= (1, 2))),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultiOutputClassifier(RandomForestClassifier(min_samples_split=2, n_estimators=20)))\n",
    "                    ])\n",
    "    \n",
    "    # specify parameters for grid search\n",
    "    parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'clf__estimator__n_estimators': [5, 10, 20],\n",
    "                  'clf__estimator__min_samples_split': [2, 5]\n",
    "                 }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6194e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "    ''' calculate the f1 score for each category and overall average\n",
    "    Args:\n",
    "        model: trained model\n",
    "        X_test: test data\n",
    "        y_test: expected output for X_test\n",
    "        category_names: list of categories / features\n",
    "    Return:\n",
    "        print f1 score for categories and average over all categories\n",
    "        df_results: pandas dataframe with all results\n",
    "    '''\n",
    "    # make model predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Creating a dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    # looping though all categories an storing their precision, recall and f1_score\n",
    "    for i in range(0, 36):\n",
    "        precision, recall, fscore, support = score(y_test.iloc[:,i],y_pred[:,i],average='weighted')\n",
    "        # adding results to the dictionary\n",
    "        results[category_names[i]] = [precision, recall, fscore]\n",
    "\n",
    "    # Creating pandas dataframe with results\n",
    "    df_results = pd.DataFrame.from_dict(results, orient='index', columns=['precision', 'recall', 'fscore'])\n",
    "    \n",
    "    # printing overall modell performance\n",
    "    print('overall f1_score: {}\\n'.format(df_results.fscore.mean()))\n",
    "    \n",
    "    # printing category results\n",
    "    print(df_results)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d3a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_filepath):\n",
    "    ''' save the model to disk\n",
    "    Arg:\n",
    "        model: Machine learning model\n",
    "        model_filepath: str path to file\n",
    "    returns: None\n",
    "    '''\n",
    "    # save the model to dish to model_filepath\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9137e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filepath = '../data/DisasterResponse.db'\n",
    "model_filepath = '../models/classifier.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630d3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: ../data/DisasterResponse.db\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5881bdff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1296df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(ngram_range=(1, 2),\n",
       "                                                        tokenizer=&lt;function tokenize at 0x000001430E0C73A0&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=20)))]),\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [5, 10, 20],\n",
       "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (1, 2)]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(ngram_range=(1, 2),\n",
       "                                                        tokenizer=&lt;function tokenize at 0x000001430E0C73A0&gt;)),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=20)))]),\n",
       "             param_grid={&#x27;clf__estimator__min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;clf__estimator__n_estimators&#x27;: [5, 10, 20],\n",
       "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (1, 2)]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=&lt;function tokenize at 0x000001430E0C73A0&gt;)),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=20)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2),\n",
       "                tokenizer=&lt;function tokenize at 0x000001430E0C73A0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">clf: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=20))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=20)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=20)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(ngram_range=(1, 2),\n",
       "                                                        tokenizer=<function tokenize at 0x000001430E0C73A0>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=20)))]),\n",
       "             param_grid={'clf__estimator__min_samples_split': [2, 5],\n",
       "                         'clf__estimator__n_estimators': [5, 10, 20],\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e9cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "overall f1_score: 0.9352162818167749\n",
      "\n",
      "                        precision    recall    fscore\n",
      "related                  0.796063  0.809651  0.796328\n",
      "request                  0.889799  0.894335  0.882908\n",
      "offer                    0.989348  0.994660  0.991996\n",
      "aid_related              0.766568  0.767690  0.764845\n",
      "medical_help             0.903776  0.922182  0.893064\n",
      "medical_products         0.944599  0.950601  0.933168\n",
      "search_and_rescue        0.970046  0.974442  0.962726\n",
      "security                 0.983313  0.983025  0.974797\n",
      "military                 0.960113  0.969483  0.956847\n",
      "child_alone              1.000000  1.000000  1.000000\n",
      "water                    0.957066  0.959374  0.953488\n",
      "food                     0.938276  0.941255  0.936543\n",
      "shelter                  0.928904  0.935152  0.923599\n",
      "clothing                 0.983737  0.985504  0.980336\n",
      "money                    0.971466  0.978066  0.968286\n",
      "missing_people           0.982304  0.987984  0.982381\n",
      "refugees                 0.957776  0.966431  0.951691\n",
      "death                    0.961910  0.964715  0.955102\n",
      "other_aid                0.821614  0.868587  0.818445\n",
      "infrastructure_related   0.864144  0.928858  0.895333\n",
      "transport                0.948805  0.955560  0.936427\n",
      "buildings                0.948073  0.956323  0.942954\n",
      "electricity              0.979243  0.981881  0.973937\n",
      "tools                    0.988210  0.994087  0.991140\n",
      "hospitals                0.978752  0.989319  0.984007\n",
      "shops                    0.987072  0.993515  0.990283\n",
      "aid_centers              0.972723  0.986267  0.979449\n",
      "other_infrastructure     0.917885  0.952508  0.930267\n",
      "weather_related          0.871833  0.873927  0.868111\n",
      "floods                   0.944112  0.947549  0.937625\n",
      "storm                    0.928511  0.935533  0.925003\n",
      "fire                     0.990929  0.990845  0.986472\n",
      "earthquake               0.965863  0.967194  0.965746\n",
      "cold                     0.975632  0.980164  0.972699\n",
      "other_weather            0.928382  0.950792  0.929484\n",
      "direct_report            0.846958  0.854854  0.832298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.796063</td>\n",
       "      <td>0.809651</td>\n",
       "      <td>0.796328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.889799</td>\n",
       "      <td>0.894335</td>\n",
       "      <td>0.882908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.989348</td>\n",
       "      <td>0.994660</td>\n",
       "      <td>0.991996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.766568</td>\n",
       "      <td>0.767690</td>\n",
       "      <td>0.764845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.903776</td>\n",
       "      <td>0.922182</td>\n",
       "      <td>0.893064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.944599</td>\n",
       "      <td>0.950601</td>\n",
       "      <td>0.933168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.970046</td>\n",
       "      <td>0.974442</td>\n",
       "      <td>0.962726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.983313</td>\n",
       "      <td>0.983025</td>\n",
       "      <td>0.974797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.960113</td>\n",
       "      <td>0.969483</td>\n",
       "      <td>0.956847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.957066</td>\n",
       "      <td>0.959374</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.938276</td>\n",
       "      <td>0.941255</td>\n",
       "      <td>0.936543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.928904</td>\n",
       "      <td>0.935152</td>\n",
       "      <td>0.923599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983737</td>\n",
       "      <td>0.985504</td>\n",
       "      <td>0.980336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.971466</td>\n",
       "      <td>0.978066</td>\n",
       "      <td>0.968286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.982304</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>0.982381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.957776</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>0.951691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.961910</td>\n",
       "      <td>0.964715</td>\n",
       "      <td>0.955102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.821614</td>\n",
       "      <td>0.868587</td>\n",
       "      <td>0.818445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.864144</td>\n",
       "      <td>0.928858</td>\n",
       "      <td>0.895333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.948805</td>\n",
       "      <td>0.955560</td>\n",
       "      <td>0.936427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.948073</td>\n",
       "      <td>0.956323</td>\n",
       "      <td>0.942954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979243</td>\n",
       "      <td>0.981881</td>\n",
       "      <td>0.973937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.988210</td>\n",
       "      <td>0.994087</td>\n",
       "      <td>0.991140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.978752</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>0.984007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.987072</td>\n",
       "      <td>0.993515</td>\n",
       "      <td>0.990283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.972723</td>\n",
       "      <td>0.986267</td>\n",
       "      <td>0.979449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.917885</td>\n",
       "      <td>0.952508</td>\n",
       "      <td>0.930267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.871833</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.868111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.944112</td>\n",
       "      <td>0.947549</td>\n",
       "      <td>0.937625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.928511</td>\n",
       "      <td>0.935533</td>\n",
       "      <td>0.925003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.990929</td>\n",
       "      <td>0.990845</td>\n",
       "      <td>0.986472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.965863</td>\n",
       "      <td>0.967194</td>\n",
       "      <td>0.965746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.975632</td>\n",
       "      <td>0.980164</td>\n",
       "      <td>0.972699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.928382</td>\n",
       "      <td>0.950792</td>\n",
       "      <td>0.929484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.846958</td>\n",
       "      <td>0.854854</td>\n",
       "      <td>0.832298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall    fscore\n",
       "related                  0.796063  0.809651  0.796328\n",
       "request                  0.889799  0.894335  0.882908\n",
       "offer                    0.989348  0.994660  0.991996\n",
       "aid_related              0.766568  0.767690  0.764845\n",
       "medical_help             0.903776  0.922182  0.893064\n",
       "medical_products         0.944599  0.950601  0.933168\n",
       "search_and_rescue        0.970046  0.974442  0.962726\n",
       "security                 0.983313  0.983025  0.974797\n",
       "military                 0.960113  0.969483  0.956847\n",
       "child_alone              1.000000  1.000000  1.000000\n",
       "water                    0.957066  0.959374  0.953488\n",
       "food                     0.938276  0.941255  0.936543\n",
       "shelter                  0.928904  0.935152  0.923599\n",
       "clothing                 0.983737  0.985504  0.980336\n",
       "money                    0.971466  0.978066  0.968286\n",
       "missing_people           0.982304  0.987984  0.982381\n",
       "refugees                 0.957776  0.966431  0.951691\n",
       "death                    0.961910  0.964715  0.955102\n",
       "other_aid                0.821614  0.868587  0.818445\n",
       "infrastructure_related   0.864144  0.928858  0.895333\n",
       "transport                0.948805  0.955560  0.936427\n",
       "buildings                0.948073  0.956323  0.942954\n",
       "electricity              0.979243  0.981881  0.973937\n",
       "tools                    0.988210  0.994087  0.991140\n",
       "hospitals                0.978752  0.989319  0.984007\n",
       "shops                    0.987072  0.993515  0.990283\n",
       "aid_centers              0.972723  0.986267  0.979449\n",
       "other_infrastructure     0.917885  0.952508  0.930267\n",
       "weather_related          0.871833  0.873927  0.868111\n",
       "floods                   0.944112  0.947549  0.937625\n",
       "storm                    0.928511  0.935533  0.925003\n",
       "fire                     0.990929  0.990845  0.986472\n",
       "earthquake               0.965863  0.967194  0.965746\n",
       "cold                     0.975632  0.980164  0.972699\n",
       "other_weather            0.928382  0.950792  0.929484\n",
       "direct_report            0.846958  0.854854  0.832298"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Evaluating model...')\n",
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d566ba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "    MODEL: ../models/classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(model, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ba101a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: -f\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Table disaster_messages not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide the filepath of the disaster messages database \u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[0;32m     24\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas the first argument and the filepath of the pickle file to \u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[0;32m     25\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave the model to as the second argument. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExample: python \u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[0;32m     26\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_classifier.py ../data/DisasterResponse.db classifier.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m database_filepath, model_filepath \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    DATABASE: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(database_filepath))\n\u001b[1;32m----> 5\u001b[0m X, Y, category_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(database_filepath)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# load data from database\u001b[39;00m\n\u001b[0;32m     15\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(database_filepath))\n\u001b[1;32m---> 16\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisaster_messages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# As feature is used the messages (translated in english)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:286\u001b[0m, in \u001b[0;36mread_sql_table\u001b[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    284\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(table_name):\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m table \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    289\u001b[0m     table_name,\n\u001b[0;32m    290\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    295\u001b[0m )\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Table disaster_messages not found"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if len(sys.argv) == 3:\n",
    "        database_filepath, model_filepath = sys.argv[1:]\n",
    "        print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "        X, Y, category_names = load_data(database_filepath)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "        print('Building model...')\n",
    "        model = build_model()\n",
    "\n",
    "        print('Training model...')\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        print('Evaluating model...')\n",
    "        evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "        print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "        save_model(model, model_filepath)\n",
    "\n",
    "        print('Trained model saved!')\n",
    "\n",
    "    else:\n",
    "        print('Please provide the filepath of the disaster messages database '\\\n",
    "              'as the first argument and the filepath of the pickle file to '\\\n",
    "              'save the model to as the second argument. \\n\\nExample: python '\\\n",
    "              'train_classifier.py ../data/DisasterResponse.db classifier.pkl')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d73ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd7275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416198d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
